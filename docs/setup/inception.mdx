Perfect, thank you. I’ll put together a complete step-by-step workflow for building full-stack React/Next.js applications using Cursor with strict PRD, UX, and technical guidelines enforced through Cursor’s system instructions and agent rules. This will include:

- How to structure and generate key documents (PRD, UX, Tech Specs) in Markdown.
- System prompts for GBT to elicit necessary details from you.
- Guidance for setting up Cursor's new rules feature.
- Ensuring testing (Jest) and software development plans are integrated.

I'll let you know as soon as the full guide is ready.

# Full-Stack App Development Workflow with Cursor (Solo Developer Guide)

Building a full-stack application as a solo developer can be streamlined using Cursor’s AI-powered IDE. Below is a step-by-step workflow to ensure consistency, testability, and context-aware development by leveraging project documentation, Cursor’s **Rules** feature, and GPT-based agents. This guide will help you set up your project with clear documentation, configure the AI’s behavior to follow your guidelines, and iterate on features with built-in testing and review.

## 1. Establish Key Project Documentation (PRD, UX Guide, Tech Spec)

Begin by creating three core Markdown documents in your project (e.g. in a `docs/` or `.notes/` directory ([Mastering Long Codebases with Cursor, Gemini, and Claude: A Practical Guide - How To - Cursor - Community Forum](https://forum.cursor.com/t/mastering-long-codebases-with-cursor-gemini-and-claude-a-practical-guide/38240#:~:text=1,notes))): a **Product Requirements Document (PRD)**, a **UX Guidance Document**, and a **Technical Specification Document**. These serve as the “source of truth” for both you and the AI ([Best Practices for Using PRDs with Cursor | ChatPRD Resources](https://www.chatprd.ai/resources/PRD-for-Cursor#:~:text=In%20AI,truth%20about%20your%20product%27s%20goals)).

- **Product Requirements Document (PRD):** Describes *what* the product should do. Include the product goals, target users, and a breakdown of features and functionality ([Best Practices for Using PRDs with Cursor | ChatPRD Resources](https://www.chatprd.ai/resources/PRD-for-Cursor#:~:text=In%20this%20new%20coding%20workflow%2C,essentially%20a%20blueprint%20for%20development)). Structure the PRD with clear sections and use consistent headings for each area ([Best Practices for Using PRDs with Cursor | ChatPRD Resources](https://www.chatprd.ai/resources/PRD-for-Cursor#:~:text=,Cursor%20pick%20up%20on%20specific)). Common sections are:
  - **Problem Statement / Goals:** High-level summary of the app’s purpose and user value.
  - **Key Features & User Stories:** A list of features with short user-story descriptions (e.g. “As a *[user role]*, I want *[capability]* so that *[benefit]*”). Write each user story clearly and isolate distinct requirements ([Best Practices for Using PRDs with Cursor | ChatPRD Resources](https://www.chatprd.ai/resources/PRD-for-Cursor#:~:text=into%20your%20PRD%3F%20Check%20out,criteria%20as%20bullet%20points%20for)).
  - **Acceptance Criteria:** For each feature or story, list bullet-point criteria that must be met for it to be “done.” These should capture edge cases and expected behaviors (e.g. *“Password reset link expires after 15 minutes and shows error if expired.”*) Writing explicit acceptance criteria helps the AI generate code that meets all conditions ([Best Practices for Using PRDs with Cursor | ChatPRD Resources](https://www.chatprd.ai/resources/PRD-for-Cursor#:~:text=long%20paragraph%20%E2%80%93%20split%20them,guide%20code%20suggestions%20that%20meet)).
  - **Constraints:** Any non-negotiable requirements or limitations (technical, business, or compliance). For example, supported platforms, performance requirements, or forbidden tech. Clearly listing constraints ensures the AI won’t propose solutions that violate them ([Best Practices for Using PRDs with Cursor | ChatPRD Resources](https://www.chatprd.ai/resources/PRD-for-Cursor#:~:text=10%2C000%20concurrent%20users%3B%20no%20external,to%20manage%20workflow%E2%80%9D%2C%20Cursor%20can)) ([Best Practices for Using PRDs with Cursor | ChatPRD Resources](https://www.chatprd.ai/resources/PRD-for-Cursor#:~:text=,consistent%20format%20for%20similar%20items)).
  
- **UX Guidance Document:** Details the *design and user experience* guidelines. This is effectively a style guide for your application’s front-end:
  - **Design Principles:** Overall UX philosophy (e.g. simplicity, accessibility, mobile-first). If you have branding guidelines or a design system, note them here.
  - **Look & Feel:** Define the color palette, typography, spacing, and any UI components standards. For example, specify that all buttons follow a certain style or that a specific CSS framework (like Tailwind or Material UI) is used for consistency.
  - **UI Components & Patterns:** List common UI components or patterns (navigation bars, modals, form layouts) and how they should behave. Include any reusable components that should be used instead of creating new ones (to maintain consistency).
  - **Accessibility & UX Notes:** Any UX mandates such as keyboard navigation support, form validation behavior, etc. The AI will use this to align front-end output with expected usability guidelines.
  
  *By providing a UX guide, you ensure the AI’s front-end code respects your design choices.* (For instance, if the UX doc says *all interactive elements must have hover states and ARIA labels*, the AI should incorporate those in its suggestions.)

- **Technical Specification Document:** Describes *how* the system will be built, aligning with the PRD’s requirements:
  - **Tech Stack & Architecture:** List the frameworks, libraries, and overall architecture decisions for both front-end and back-end. For example: *“Front-end built with Next.js (React + TypeScript), back-end using Node.js with Express, MongoDB database.”* Also mention any architectural patterns (MVC, microservices, serverless, etc.) and how components interact. The AI will leverage this info – for instance, if the spec notes *“State management will use Redux”*, Cursor will factor that into its suggestions ([Best Practices for Using PRDs with Cursor | ChatPRD Resources](https://www.chatprd.ai/resources/PRD-for-Cursor#:~:text=guidelines%3A%20architecture%20outlines%2C%20data%20models%2C,2%2C%20do%20the%20same%20throughout)).
  - **Data Models and APIs:** Outline important data entities, database schema, and API contract (endpoints, request/response formats) if applicable. This gives the AI context when generating model or service code.
  - **Key Technical Constraints or Decisions:** E.g., authentication method (OAuth2, JWT), external services to integrate, performance considerations, and any known algorithms or business logic rules that must be implemented. Documenting these ensures the AI’s code suggestions align with the chosen frameworks and algorithms ([Best Practices for Using PRDs with Cursor | ChatPRD Resources](https://www.chatprd.ai/resources/PRD-for-Cursor#:~:text=includes%20a%20Technical%20Specifications%20section%2C,a%20verb%2C%20keep%20that%20style)).
  - **Non-Functional Requirements:** (Optional) Note requirements like scalability, security practices, or deployment environment if they influence code. 

Keep each document **concise, structured, and explicit**. Use Markdown headings and bullet lists liberally so that the AI can easily parse the information ([Best Practices for Using PRDs with Cursor | ChatPRD Resources](https://www.chatprd.ai/resources/PRD-for-Cursor#:~:text=,Cursor%20pick%20up%20on%20specific)) ([Best Practices for Using PRDs with Cursor | ChatPRD Resources](https://www.chatprd.ai/resources/PRD-for-Cursor#:~:text=long%20paragraph%20%E2%80%93%20split%20them,guide%20code%20suggestions%20that%20meet)). For example, clearly label sections like “## Feature: Password Reset” with sub-lists for its criteria, rather than burying details in long paragraphs. A well-structured PRD or spec is “AI-ready” – it allows Cursor to quickly find relevant details, resulting in more accurate code generation ([Best Practices for Using PRDs with Cursor | ChatPRD Resources](https://www.chatprd.ai/resources/PRD-for-Cursor#:~:text=By%20structuring%20your%20PRD%20with,clarity%20and%20organization%20are%20key)). In short, think of these docs as not only for you but also for your AI assistant: *clarity and organization are key* ([Best Practices for Using PRDs with Cursor | ChatPRD Resources](https://www.chatprd.ai/resources/PRD-for-Cursor#:~:text=By%20structuring%20your%20PRD%20with,clarity%20and%20organization%20are%20key)).

Once drafted, store these Markdown files in your project tree so that Cursor can index them (Cursor indexes your codebase and documentation to provide context to the AI ([Mastering Long Codebases with Cursor, Gemini, and Claude: A Practical Guide - How To - Cursor - Community Forum](https://forum.cursor.com/t/mastering-long-codebases-with-cursor-gemini-and-claude-a-practical-guide/38240#:~:text=Why%3A%20This%20ensures%20that%20you,project%E2%80%99s%20goals%2C%20status%2C%20and%20history))). For instance, you might have: 

```
/docs/PRD.md  
/docs/UX-Guidelines.md  
/docs/Technical-Spec.md  
/docs/Development-Plan.md   (we will set this up in a later step)
``` 

Having these files version-controlled means they evolve with your project, and the AI will always reference the latest requirements and guidelines during development.

## 2. Populate Documentation with GPT Q&A

With the blank or outlined docs in place, use Cursor’s GPT agent to help **fill in details by interviewing you**. The idea is to have the AI ask you targeted questions to flesh out each document, ensuring nothing important is overlooked. You will act as the domain expert (product owner and developer), and the AI will act as the facilitator and scribe.

**How to do it:** Open a Cursor chat (the “Agent”) and provide a **system prompt** instructing the AI to create one of the documents. For example, to create the PRD, you might start a chat with a system message like:

```markdown
**System Prompt (for PRD creation):** 
You are an assistant helping to write a Product Requirements Document for a new application. Your job is to ask me (the user) questions to gather all information needed for a complete PRD. Start by asking high-level questions about the product's goals and users, then drill down into features, user stories, and acceptance criteria. After collecting information, draft a well-structured PRD in Markdown with clear sections (Introduction, Features/User Stories, Acceptance Criteria, Constraints, etc.). Ensure the PRD is detailed and unambiguous.
```

Then, allow the AI to engage in a dialogue. It might begin by asking things like “What is the main goal of this application and who are the target users?” – answer these questions, and the AI will continue asking follow-ups (e.g. “Can you describe the core features or use cases you have in mind?”, “Do you have any specific constraints or technologies in mind?”). This guided Q&A will extract the information needed for the PRD. Finally, instruct the AI to compile the answers into the PRD.md file. The result should be a first draft of your PRD in structured Markdown.

Repeat a similar process for the **UX Guidance** and **Technical Spec** documents:

- **For the UX Guide:** Use a system prompt like: *“You are a UX designer assistant helping to create a UX guidelines document. Ask me about the desired look and feel, any style guides or design systems, accessibility requirements, and UI preferences for the app. Then produce a Markdown document summarizing the UX design principles, styling rules, and any specific UI component guidelines.”* This will prompt the AI to ask about color schemes, preferred UI style (minimalist, modern, etc.), whether we have existing brand assets, how we want forms to behave, and so on. The outcome will be a UX-Guidelines.md capturing visual and interaction standards for the project.

- **For the Technical Spec:** Use a prompt like: *“You are a software architect assistant helping to write a Technical Specification document. Ask me about the chosen tech stack, architecture, data models, and key technical requirements. Then generate a Markdown document outlining the architecture, technology choices, data schema, API design, and any important technical constraints.”* The AI may ask which front-end and back-end frameworks you plan to use, database choices, how you plan to host the app, any third-party services, etc. Provide all relevant details. The AI then drafts a Technical-Spec.md with sections like “Tech Stack,” “Architecture Diagram (described in text),” “Data Models,” “APIs/Endpoints,” and so forth.

During these Q&A sessions, **be as thorough as possible** in your answers. If the AI doesn’t ask about something you know is important, proactively mention it. For example, if security or performance is crucial, bring it up even if not explicitly asked. The goal is to fully populate these docs with everything *you* know about the project’s requirements and plans. This front-loads context into your project so you won’t have to explain it repeatedly later.

After each document is generated, **review and edit the content** to ensure accuracy. GPT can draft quickly, but you should verify it captured your intentions correctly and add any missing details. The PRD in particular should be checked against your vision – ensure the user stories and acceptance criteria truly reflect what you want.

In summary, by the end of this step you will have a fleshed-out **PRD.md**, **UX-Guidelines.md**, and **Technical-Spec.md** in your repository. These will serve as the guardrails for all coding to come. In fact, providing a well-structured PRD to Cursor gives the AI a clear *source of truth about your product’s goals*, keeping it aligned with what needs to be built ([Best Practices for Using PRDs with Cursor | ChatPRD Resources](https://www.chatprd.ai/resources/PRD-for-Cursor#:~:text=In%20AI,truth%20about%20your%20product%27s%20goals)). The same goes for the UX and tech docs – they establish boundaries for design and implementation that the AI will respect.

*(Tip: This process not only guides the AI, but it also helps you clarify the project for yourself. The act of answering the AI’s questions can reveal requirements you hadn’t considered or areas that need more thought.)*

## 3. Configure Cursor’s Rules for Context and Consistency

Now that you have your key documents, it’s time to set up Cursor’s **Rules** feature to make the AI consistently follow those docs and other project conventions. Cursor rules allow you to provide persistent, system-level instructions to the AI ([Cursor – Rules](https://docs.cursor.com/context/rules#:~:text=Large%20language%20models%20do%20not,context%20at%20the%20prompt%20level)). Think of rules as a way to encode your project’s standards and context so you don’t have to repeat them in every prompt.

**Where to define rules:** In your project, create a directory called `.cursor/rules/`. You can create multiple rule files here, each with a specific scope or purpose ([Cursor – Rules](https://docs.cursor.com/context/rules#:~:text=Project%20rules)) ([Design document & wireframes - Discussion - Cursor - Community Forum](https://forum.cursor.com/t/design-document-wireframes/49086#:~:text=You%20can%20structure%20all%20of,and%20accessible%20to%20the%20AI)). (Alternatively, you can use a single legacy `.cursorrules` file at the root, but the multiple-files approach is more organized and future-proof ([Best Practices for Using PRDs with Cursor | ChatPRD Resources](https://www.chatprd.ai/resources/PRD-for-Cursor#:~:text=or%20many%2C%20make%20sure%20to,AI%20outputs%20that%20need%20guidance)).) Each rule file is written in Markdown (Cursor uses an `.mdc` extension for rule files) with a bit of front-matter to define how it’s applied (e.g. “Always” rules are always included) ([Cursor – Rules](https://docs.cursor.com/context/rules#:~:text=Large%20language%20models%20do%20not,context%20at%20the%20prompt%20level)).

Set up the following rules to enforce usage of your docs, testing, and planning:

- **Rule: Always reference requirements and guidelines** – Create a rule file (e.g. `project_context.mdc`) of type **Always** that reminds the AI to use the PRD, UX, and Tech Spec as guiding context. For example, the content might say: *“Always adhere to the project’s requirements and standards. Refer to **PRD.md** for feature definitions and acceptance criteria, **UX-Guidelines.md** for design/UX standards, and **Technical-Spec.md** for architecture and tech stack info. Do not implement features or behaviors not described in the PRD. If something is unclear or unspecified, ask for clarification rather than assuming.”* By including such a rule, you ensure the AI is constantly anchored to your documentation when generating or modifying code. In effect, this makes your docs act like a persistent system prompt for the project ([Best Practices for Using PRDs with Cursor | ChatPRD Resources](https://www.chatprd.ai/resources/PRD-for-Cursor#:~:text=What%20are%20Cursor%20rules%3F%20In,obey%20them%20in%20its%20suggestions)) ([Best Practices for Using PRDs with Cursor | ChatPRD Resources](https://www.chatprd.ai/resources/PRD-for-Cursor#:~:text=)). (This addresses “staying within guardrails” – the AI will be less likely to veer off into unwanted functionality or styles.)

- **Rule: Enforce tech stack and coding conventions** – If your Technical Spec or team preferences dictate certain frameworks or coding styles, encode them in rules as well. For instance, if you decided on Next.js with TypeScript for the front-end, you might add: *“Use Next.js (React 18) with TypeScript for all front-end code. Prefer functional components and React Hooks over class components.”* Similarly, for a back-end: *“Use Express.js for API endpoints; follow RESTful API design.”* You can also include style guidelines: *“Follow the ESLint config rules; code should pass linting.”* These instructions will ensure consistency in the AI’s output. For example, by stating “all React components should be functional,” the AI will avoid suggesting class-based components ([Best Practices for Using PRDs with Cursor | ChatPRD Resources](https://www.chatprd.ai/resources/PRD-for-Cursor#:~:text=,%E2%80%9D)). If you specify “use axios for HTTP requests, not fetch,” it will abide, rather than mixing libraries ([Best Practices for Using PRDs with Cursor | ChatPRD Resources](https://www.chatprd.ai/resources/PRD-for-Cursor#:~:text=include%3A)). By encoding such points, you avoid inconsistent suggestions and save time in reviews ([Best Practices for Using PRDs with Cursor | ChatPRD Resources](https://www.chatprd.ai/resources/PRD-for-Cursor#:~:text=By%20encoding%20such%20points%2C%20you,inconsistency%20or%20extra%20review%20work)).

- **Rule: Testing requirements** – A crucial rule file should cover automated testing. Title it something like `testing_policy.mdc`. In it, instruct: *“All new features or code changes **must include** corresponding tests. Write unit tests for all functions/components using Jest. Also provide integration or end-to-end tests for features where applicable (for example, user flows through the UI, using a tool like Playwright or Cypress). The AI should output test code alongside implementation code whenever a new feature or module is created.”* This ensures that whenever you ask the AI to implement something, it knows that tests are not optional but a required part of the deliverable. You can be specific, e.g.: “When adding a React component, also generate a Jest test file in `__tests__/` directory to cover its behavior. When adding an API endpoint, include tests in `tests/` folder to hit that endpoint.” By making testing a rule, you **automate test inclusion** – the AI will proactively produce test code without needing a separate prompt each time. This addresses the goal of “automatically including Jest-based unit tests and end-to-end tests with any feature implementation.” In practice, developers have found that when the AI writes tests along with code, it provides a level of assurance that the code works as intended ([How I use Cursor (+ my best tips)](https://www.builder.io/blog/cursor-tips#:~:text=match%20at%20L544%20Here%27s%20where,at%20least%20doing%20something%20right)) (if the tests pass). It also forces the AI to consider edge cases (often captured in your PRD’s acceptance criteria) during development.

- **Rule: Maintain a development plan** – We also want the AI to be aware of our project management to some extent. Create a Markdown file for your **Software Development Plan** (e.g. `Development-Plan.md` or `task_list.md`) that lists planned features, their priority, and status. This can be a simple checklist or to-do list in Markdown. For example: 

  ```markdown
  # Development Plan
  
  ## Backlog
  - [ ] **Login Feature** – *Priority: High.* (Status: To Do)  
  - [ ] **User Profile Page** – *Priority: Medium.* (Status: To Do)
  
  ## In Progress
  - [ ] **Password Reset** – *Priority: High.* (Status: In Progress, Assigned to AI)
  
  ## Completed
  - [x] **Setup Project Structure** – *Priority: High.* (Status: Done)
  ```
  
  This is just an example; use whatever format suits you (the key is each item shows what it is, its importance, and whether it’s not started, in progress, or done). Keeping such a task list updated will give you clarity and also provides context to the AI about project progress ([Mastering Long Codebases with Cursor, Gemini, and Claude: A Practical Guide - How To - Cursor - Community Forum](https://forum.cursor.com/t/mastering-long-codebases-with-cursor-gemini-and-claude-a-practical-guide/38240#:~:text=and%20architecture.%20,answers%20received%2C%20and%20decisions%20made)) ([Mastering Long Codebases with Cursor, Gemini, and Claude: A Practical Guide - How To - Cursor - Community Forum](https://forum.cursor.com/t/mastering-long-codebases-with-cursor-gemini-and-claude-a-practical-guide/38240#:~:text=This%20file%20is%20your%20project%E2%80%99s,priorities%2C%20and%20any%20relevant%20notes)). You can include a rule to remind the AI of this plan, for instance: *“Refer to **Development-Plan.md** for the list of features and their status. Only work on features that are in progress or explicitly requested. Mark tasks as completed in that document when implementations are done.”* While the AI won’t magically update the file on its own without being directed, this rule serves as a guideline. In practice, you (the developer) can instruct the AI to update the plan after finishing a task (or do it manually), and having it in the project means it’s always a quick reference. The plan ensures no feature is forgotten and helps prioritize the AI’s focus.

**Implementing the rules:** In each `.mdc` rule file, you may include metadata at the top to define when it applies. For simplicity, you can make most of these “Always” rules (so they’re always in the AI’s context) unless you want to scope them. For example, you might scope the testing rule to only apply when editing code files, or a UX rule to only apply to front-end files. But an easy method is to mark them Always, since they’re generally relevant to all parts of the project. According to Cursor’s docs, when a rule is applied, its content is included at the start of the model’s context for every AI operation ([Cursor – Rules](https://docs.cursor.com/context/rules#:~:text=Large%20language%20models%20do%20not,context%20at%20the%20prompt%20level)). This means every time the AI generates code or answers in chat, it will see these instructions first. 

Here is a brief example of what a section of a legacy `.cursorrules` file might look like (the new format `.cursor/rules/*.mdc` will have similar content without the bullet prefix):

```markdown
# Project Rules (Excerpt)

- Always follow the specifications in the project documents (PRD, UX-Guidelines, Technical-Spec). Do not introduce features or UI elements not described in those documents.
- Frontend must use **React 18 + Next.js** and **TypeScript** as per spec. Prefer functional components and hooks.
- UI should adhere to **UX-Guidelines.md** (use common styles and ensure accessibility).
- Backend uses **Node.js + Express**; follow REST conventions.
- Always include appropriate **Jest unit tests** for any new code, and add **Playwright e2e tests** for user-facing features.
- Do not modify unrelated code; only change what’s needed for the current task ([My Cursor AI Workflow That Actually Works | N’s Blog](https://nmn.gl/blog/cursor-guide#:~:text=,and%20logs%20before%20making%20changes)).
```

Each of those lines encodes a decision or guideline, so the AI won’t forget them. For instance, if a developer asks Cursor to create a new API endpoint, the rule above ensures the AI “already knows” it should use Express and not some other framework, without the developer repeating it ([Best Practices for Using PRDs with Cursor | ChatPRD Resources](https://www.chatprd.ai/resources/PRD-for-Cursor#:~:text=,no%20raw%20SQL%20queries)). The rule about tests ensures the AI doesn’t skip writing tests. The last rule (no unrelated changes) is a safeguard against the AI “over-reaching” – it should avoid touching parts of the code that are outside the scope of the request ([My Cursor AI Workflow That Actually Works | N’s Blog](https://nmn.gl/blog/cursor-guide#:~:text=,and%20logs%20before%20making%20changes)), maintaining strict boundaries for each change.

After writing these rules, **save them and commit them**. Because they live in your repository, they are versioned along with your code. As your project evolves, update the rules as needed. For example, if you adopt a new coding convention or add a new important guideline, edit or add a rule file. Keeping rules up-to-date is important; they are essentially the AI’s understanding of your project’s conventions ([Best Practices for Using PRDs with Cursor | ChatPRD Resources](https://www.chatprd.ai/resources/PRD-for-Cursor#:~:text=inconsistency%20or%20extra%20review%20work)). (Note: if using multiple rule files in `.cursor/rules/`, ensure you name and scope them appropriately. Cursor supports using glob patterns to auto-attach rules for certain file types or directories if desired ([Design document & wireframes - Discussion - Cursor - Community Forum](https://forum.cursor.com/t/design-document-wireframes/49086#:~:text=Here%E2%80%99s%20how%20I%E2%80%99d%20break%20it,down)), but for most solo projects a handful of global rules is sufficient.)

At this stage, you have given Cursor’s AI *persistent knowledge* of your requirements (via docs) and *instructions* on how to code (via rules). The heavy lifting of context setup is done – this will pay off by reducing errors and miscommunications later.

## 4. Feature Development Cycle: Iterative Coding, Testing, and Review

With documentation and rules in place, you can proceed to implement features in an **iterative development cycle**. The workflow for each feature (or task) typically goes as follows:

**a. Select a Feature and Understand the Requirements:** Pick a task from your Development Plan (or PRD). For example, suppose the next task is “Password Reset” user story. Before coding, revisit the PRD section for “Password Reset” and read the acceptance criteria and constraints. Ensure you (and the AI) understand exactly what needs to be built. This context is already available to the AI via the indexed docs and rules, but it can help to explicitly remind the AI of the relevant part. You could copy-paste the specific user story from PRD into the chat as context, or use an `@` reference if Cursor supports it (Cursor allows referencing files or sections in chat).

**b. Outline a Solution (Plan the Implementation):** It’s often beneficial to have the AI *propose a plan or design for the feature* before writing code. This ensures technical compliance and can catch issues early. You can prompt the AI in chat with something like: *“Given the PRD and Technical Spec, how should we implement the Password Reset feature? Please outline the steps or components needed.”* Because the AI is operating with your rules (e.g. it knows the tech stack and that it must follow the spec), it might respond with a plan such as:
  - *“1. Add a new API endpoint `/api/reset-password` in the Express server to handle reset requests (as described in PRD). 2. Create a database table or collection for password reset tokens with fields X, Y, Z. 3. Implement a function to send email with reset link (using Node mailer, per tech spec’s email service). 4. On front-end, create a `ResetPassword` page in Next.js with a form to enter new password (following UX guidelines for form design). 5. Add Jest unit tests for the token generation function and Playwright e2e test for the full reset flow.”*  

  You as the developer can review this plan. Does it align with the Technical Spec (e.g., uses the right database and email service)? Does it cover all acceptance criteria from the PRD (e.g., token expiration, confirmation messages)? If anything is missing or not according to spec, correct the plan. This step is analogous to a quick design review. It leverages the AI’s ability to “think step-by-step” as encouraged by our rules ([My Cursor AI Workflow That Actually Works | N’s Blog](https://nmn.gl/blog/cursor-guide#:~:text=,needed%20to%20gather%20more%20information)). In fact, one best practice is to have the AI present a *PLAN with reasoning* before coding ([My Cursor AI Workflow That Actually Works | N’s Blog](https://nmn.gl/blog/cursor-guide#:~:text=,needed%20to%20gather%20more%20information)) – this matches how an engineer might design first, code second. In Cursor, you could even have a rule enforcing a “blueprint” or plan phase for non-trivial tasks ([[Guide] A Simpler, More Autonomous AI Workflow for Cursor [New Update] - Showcase - Cursor - Community Forum](https://forum.cursor.com/t/guide-a-simpler-more-autonomous-ai-workflow-for-cursor-new-update/70688#:~:text=,proceeding%20to%20the%20CONSTRUCT%20phase)).

**c. Implement the Feature with AI Assistance:** Now proceed to coding. You have a few ways to do this in Cursor:
  - *In the Chat Agent:* You can literally tell the agent to write the code. For example: *“Implement the backend and frontend for the Password Reset feature as per the plan.”* Because your rules say to include tests, it should also generate test files. The agent might reply with multiple code blocks: some for back-end (Express route, token generation helper, etc.), some for front-end (React page, form handling), and some for tests (Jest test for token logic, maybe a Playwright script for e2e). If the response is too large, you might need to ask for each part separately (e.g., *“Let’s start with the backend API endpoint.”*, then *“Now the front-end page.”*, to keep the context focused).
  - *In the Editor with Cmd-K or Autocomplete:* You can create new files (e.g. `pages/reset-password.tsx`, `server/routes/resetPassword.js`, `__tests__/resetPassword.test.js`) and use Cursor’s inline suggestions. For instance, open the file, write a function signature or some comments outlining what it should do, and let Cursor autocomplete. Thanks to the indexed context and rules, it should follow your guidelines. If it doesn’t initially include tests, you can explicitly invoke a command like *“Generate Jest tests for this module”*. (Cursor’s Cmd+K palette might have such actions.)

As the AI produces code, **verify it against the PRD and Tech Spec**. Check that it meets each acceptance criterion from the PRD for that feature. Also cross-check that it uses the correct functions or modules as per your Tech Spec (e.g., if spec says to use a particular library for email, ensure the code did so). With the rules in place, the AI should already be aligned, but it’s good to manually oversee this. Pay attention to the **UX details** too: does the front-end code follow the UX guidelines? For example, if the UX doc specifies certain error message style or accessibility attributes, confirm the AI included them. If not, you can prompt the AI to fix that: *“Add ARIA labels to the form inputs as per accessibility guidelines.”* Keeping an eye on these details maintains UX consistency.

**d. Include Tests and Run Them:** By rule, the AI should have generated tests alongside the code. Commonly, it will create unit tests that cover key logic. Ensure that the tests indeed cover all critical paths (you might compare test cases to the acceptance criteria list). If something is missing, ask the AI to add a test for it (e.g., *“Write a test for the token expiration scenario.”*). Now, run the tests using your development environment (e.g. `npm test` for Jest). If all tests pass on first run, great – you have a working feature with verified behavior. Often, though, there might be failing tests or minor bugs. This is where Cursor really shines: you can copy any error messages or failing test output and ask the AI to help fix them. For instance, *“Test X is failing with message Y. Please fix the code to address this.”* The AI will use the failure output as feedback and adjust the code accordingly. This cycle can continue until tests pass. In fact, Cursor has a special “YOLO” mode where the agent can automatically run tests and debug until everything is green ([How I use Cursor (+ my best tips)](https://www.builder.io/blog/cursor-tips#:~:text=Cursor%20and%20say%2C%20,until%20all%20the%20tests%20pass)) – essentially, the AI keeps coding and running tests in a loop, which the Cursor team calls *“verify the code is correct beyond just lint”* ([How I use Cursor (+ my best tips)](https://www.builder.io/blog/cursor-tips#:~:text=match%20at%20L496%20One%20of,to%20turn%20on%20YOLO%20mode)). With such a mode, one could even say: *“Run the test suite and fix any issues until all tests pass.”* (Use with caution – it’s powerful but you still want to review changes. Whether manually or automatically, leveraging tests to validate code is a huge advantage ([How I use Cursor (+ my best tips)](https://www.builder.io/blog/cursor-tips#:~:text=match%20at%20L544%20Here%27s%20where,at%20least%20doing%20something%20right)).)

**e. Code Review and Refinement:** Even after tests pass, do a quick review of the new code (either manually or by asking the AI to review it). For instance, ask: *“Review the new code for any style issues or anything that doesn’t follow our tech spec and UX guidelines.”* The AI might point out if anything deviates from the rules or common best practices. Because we instructed it with rules, it likely won’t find major issues, but it could catch things like a missing comment or an edge-case not handled. This is akin to having a second pair of eyes. Always ensure the code is clean and understandable – solo developers benefit later from well-documented code. If the AI's output is a bit messy (maybe variable names not ideal, or code not optimally structured), you can prompt it to refactor: *“Refactor this code for clarity and maintainability.”* Given the context and rules, it will maintain correctness while perhaps simplifying the logic or improving naming.

**f. Update Documentation and Plan:** With the feature complete and tested, update your documents:
  - Mark the feature as **Completed** in your Development Plan (e.g., tick the checkbox in `Development-Plan.md` and move it to a Completed section). This helps track progress ([Mastering Long Codebases with Cursor, Gemini, and Claude: A Practical Guide - How To - Cursor - Community Forum](https://forum.cursor.com/t/mastering-long-codebases-with-cursor-gemini-and-claude-a-practical-guide/38240#:~:text=)) ([Mastering Long Codebases with Cursor, Gemini, and Claude: A Practical Guide - How To - Cursor - Community Forum](https://forum.cursor.com/t/mastering-long-codebases-with-cursor-gemini-and-claude-a-practical-guide/38240#:~:text=)).
  - If implementing the feature revealed any changes needed in the PRD or Tech Spec (maybe you discovered a new constraint or adjusted a requirement), update those docs too so they remain accurate. Consistency between docs and code is important for future AI context.
  - Consider adding a brief note in the PRD or an adjunct document about how the feature was implemented if it’s not obvious – essentially documenting the solution. This can help later if the AI or you need to revisit it.

Now commit your changes (including code, tests, and any doc updates). You can even use Cursor’s AI to generate the commit message describing the feature ([My Cursor AI Workflow That Actually Works | N’s Blog](https://nmn.gl/blog/cursor-guide#:~:text=The%20biggest%20game,code%20for%20your%20specific%20project)).

This cycle (plan -> implement -> test -> review -> document) should be repeated for each feature or task on your list. Keep each iteration focused: tackle one feature at a time (or one sub-feature, if it’s large) rather than asking the AI to do many unrelated things at once. This incremental approach aligns with agile principles and prevents the AI from getting confused or producing entangled code. It also ensures that if something goes wrong, it’s easier to pinpoint (since changes are scoped).

Throughout development, always circle back to your PRD and rules whenever there’s uncertainty. For example, if the AI outputs something that seems odd, check if it misinterpreted a requirement – maybe the PRD needs clarification. Keeping the documentation, the rules, and the code in sync is a recipe for a smooth development process where the AI truly acts as your pair programmer rather than a distractible junior dev.

## 5. Tips and Best Practices for Solo Developers Using Cursor AI Agents

Finally, here are some additional tips and settings to help you get the most out of Cursor’s AI as a solo developer, ensuring high output and reliability with extensibility in mind but maintaining strict boundaries:

- **Leverage Powerful Models and Ample Context:** Cursor allows use of models like GPT-4 (and even Claude). If possible, use GPT-4 for complex tasks as it generally produces higher-quality code and follows instructions better. Additionally, if your docs are large, consider models with extended context windows (GPT-4-32k or Claude 100k) so that your entire PRD/Spec can fit in context when needed. This prevents the AI from “forgetting” earlier parts of the conversation or project details. The integrated context (project indexing + rules) already gives Cursor an edge in understanding your codebase ([My take on Cursor AI after using it at least 5 times a day | by Rohit Ghumare | Medium](https://ghumare64.medium.com/my-take-on-cursor-ai-after-using-it-at-least-5-times-a-day-f9d3ff94b84a#:~:text=Superior%20Context%20Awareness)), so combine that with a strong model.

- **Keep Prompts Focused and Bounded:** Even though the AI has all your context, try to ask one feature or issue at a time. Avoid mega-prompts that say “Build my entire app frontend” in one go – that might overwhelm or lead the AI to produce superficial results. Instead, break problems down (our rules even encourage this) and tackle them stepwise. This not only yields better results but also retains the **extensibility** of your code, because each piece is built with intention and clarity. If you need to achieve a big outcome, outline a plan and then implement in parts as described. The AI is good at following step-by-step plans ([My Cursor AI Workflow That Actually Works | N’s Blog](https://nmn.gl/blog/cursor-guide#:~:text=,needed%20to%20gather%20more%20information)), especially ones it helped draft.

- **Use “Strict Mode” in your Guidance:** By this we mean set clear boundaries. We did this through rules and well-defined requirements. If the AI does something out of those bounds, don’t hesitate to correct it. For example, if it tries to introduce a new library “to be helpful” but your Tech Spec didn’t allow it, point that out: *“Our Tech Spec says to use X for this, not Y. Please redo using X.”* The AI will apologize and fix it (the rules you set will back you up here). Keeping these boundaries ensures the final product stays on the intended path and doesn’t accumulate unexpected tech debt. 

- **Ask for Clarification or Justification:** Treat the AI like a junior developer who should justify their decisions. If you see a piece of code and wonder why it did that, ask: *“Can you explain why this approach was used?”* This serves two purposes: it ensures the AI was reasoning correctly (and not hallucinating a requirement), and it produces documentation you can later refer to. Sometimes the AI might realize it made a wrong assumption and correct it upon explanation. This keeps the AI **accountable to the plan and rules**.

- **Use Multi-Modal Aids (if available):** Cursor has features like `@docs` to include external documentation, and web search integration ([Cursor AI: A Guide With 10 Practical Examples | DataCamp](https://www.datacamp.com/tutorial/cursor-ai-code-editor#:~:text=Cursor%20also%20integrates%20advanced%20chat,features%20to%20facilitate%20better%20interaction)). As a solo dev, you might not know every API detail. You can ask the AI to pull in official docs for a library using `@Docs` (as mentioned in the forum, e.g., including Apple’s docs for an iOS project ([Design document & wireframes - Discussion - Cursor - Community Forum](https://forum.cursor.com/t/design-document-wireframes/49086#:~:text=3,detailed%20specs%20using%20%40file%20syntax))). This can help the AI give more accurate code using third-party APIs. Essentially, don’t limit the AI to just your project files – use documentation references for more context when needed.

- **Take Advantage of Cursor’s Advanced Features:** The Cursor editor has some powerful tools:
  - **Floating Chat & Inline Edits:** You can highlight a block of code and ask Cursor’s agent to refactor or explain it. This is great for quick improvements (e.g., “optimize this function”).
  - **AI Commit Messages:** Cursor can draft commit messages based on diffs ([Cursor – Rules](https://docs.cursor.com/context/rules#:~:text=,Keyboard%20Shortcuts)) – use this to maintain good project history easily.
  - **YOLO Mode (Automated Fixer):** As mentioned, enabling YOLO mode allows the AI to run tests or build commands and auto-correct issues. For a solo dev, this can dramatically speed up the “debug and fix” loop. For example, you can instruct: *“Run the build and fix any TypeScript errors until it compiles clean.”* The AI will iterate on that ([How I use Cursor (+ my best tips)](https://www.builder.io/blog/cursor-tips#:~:text=Here%27s%20what%20you%20do%3A%20Just,over%20to%20Cursor%20and%20say)) ([How I use Cursor (+ my best tips)](https://www.builder.io/blog/cursor-tips#:~:text=whatever%2C%20who%20cares,tell%20Cursor%20to%20fix%20everything)). This is like having a script that continuously tries to compile and fixes mistakes, which is a huge time-saver once your tests/build processes are set up. Just keep an eye to ensure the fixes make sense.
  - **Version Control and Branching:** Even though you’re solo, use branches for major features and feel free to experiment with the AI in separate branches. If the AI’s suggestion goes awry, you can revert or compare against the main branch easily. This safety net lets you try the AI’s more daring suggestions without permanent damage.
  
- **Test-Driven Development (TDD) with AI:** You can flip the workflow and do TDD – write (or have AI write) tests *first*, then implement code to pass them ([How to tell Cursor AI to generate unit tests using Jest with 100% coverage goals? | Rapid Dev](https://www.rapidevelopers.com/cursor-tutorial/how-to-tell-cursor-ai-to-generate-unit-tests-using-jest-with-100-coverage-goals#:~:text=menu%2C%20depending%20on%20your%20setup,logical%20branches%20within%20your%20code)). This works well if your acceptance criteria are clear. For instance, you can prompt: *“Write a Jest test suite for the Password Reset feature according to these criteria: (list criteria).”* Let the AI generate failing tests, review them to ensure they match the spec, then proceed to implement the feature until tests pass. This guarantees your implementation fulfills the PRD. Many Cursor users report success with a test-first approach since the AI knows what target it’s aiming for and then “fills in” the code.

- **Maintain Extensibility:** As you build, occasionally think ahead. If a particular design decision could make future extensions easier, ensure the AI is aware. For example, *modularity*: If you foresee adding more authentication methods later, have the AI implement the auth in a modular way now (maybe via a strategy pattern). You can mention such forward-looking requirements in the Tech Spec and even in the rules. The key is to strike a balance: you want your code to be extensible but not over-engineered for features that might never come. The AI tends to generalize code by default; your PRD and Tech Spec can scope it. If you find the AI is *over-generalizing*, rein it in by emphasizing YAGNI (you ain’t gonna need it) principle in your instructions. Conversely, if it’s writing very narrow code that will be hard to extend, prompt it to refactor for flexibility (for example, *“Refactor this to allow easy addition of new user roles in the future”*).

- **Single Source of Truth:** Now that you have multiple sources of context (PRD, spec, UX doc, rules, plan, tests), keep them consistent. As a solo dev, you have control over everything – use that to your advantage. Update documents when decisions change, and propagate important updates into the rules if needed. This avoids confusion for the AI. Remember, Cursor’s AI uses your code and docs as context; if they conflict, it might get confused. So, for example, if you decide to switch from MongoDB to PostgreSQL mid-project, update the Tech Spec and maybe add a rule line about using SQL (and remove the old Mongo references) to avoid the AI suggesting the wrong code style.

- **Continuous Learning:** Over time, observe where the AI excels and where it struggles in your workflow. If you notice it making a particular mistake repeatedly, consider adding a specific rule to address it (this is how you gradually refine your `.cursor/rules`). For instance, if it kept forgetting to add loading spinners for async actions in the UI, you could add: “Always include a loading state in UX for async operations.” The beauty of Cursor is you can tweak the AI’s behavior incrementally ([My Cursor AI Workflow That Actually Works | N’s Blog](https://nmn.gl/blog/cursor-guide#:~:text=Don%E2%80%99t%20overthink%20your%20rules%20file,what%20there%20is%20to%20know)). Start with a few core rules and add to them whenever you see the need.

By following this structured workflow, you effectively pair program with GPT-4 (or another model) in Cursor. You set the high-level direction with your documents and rules, and then let the AI handle the rote coding under those constraints. The result is a consistent, test-covered codebase that aligns with your product requirements and design vision. Both you and the AI stay on the same page thanks to the shared context. As a solo developer, this can significantly boost your productivity while maintaining code quality and project organization.

**Conclusion:** Using Cursor for full-stack development means you’re never truly “solo” – you have a powerful AI assistant at your side. But to harness it effectively, you must play the roles of architect, product manager, and lead developer up front: define what needs to be done (PRD), how it should look and feel (UX guide), and how it should be built (Tech Spec), and set clear rules. Once that foundation is laid, the AI can execute within those boundaries, producing code quickly and reliably. Always keep the development loop tight: small feature -> test -> validate against docs -> refine. With practice, you’ll find that you can build out a complex React/Next.js front-end and accompanying back-end much faster than coding everything by hand, all while preserving a high level of structure and quality. Happy coding!

**Sources:**

- ChatPRD – *“Best Practices for Using PRDs with Cursor”* ([Best Practices for Using PRDs with Cursor | ChatPRD Resources](https://www.chatprd.ai/resources/PRD-for-Cursor#:~:text=In%20this%20new%20coding%20workflow%2C,essentially%20a%20blueprint%20for%20development)) ([Best Practices for Using PRDs with Cursor | ChatPRD Resources](https://www.chatprd.ai/resources/PRD-for-Cursor#:~:text=,Cursor%20pick%20up%20on%20specific)) ([Best Practices for Using PRDs with Cursor | ChatPRD Resources](https://www.chatprd.ai/resources/PRD-for-Cursor#:~:text=long%20paragraph%20%E2%80%93%20split%20them,guide%20code%20suggestions%20that%20meet))  
- ChatPRD – *Using Cursor rules for consistency* ([Best Practices for Using PRDs with Cursor | ChatPRD Resources](https://www.chatprd.ai/resources/PRD-for-Cursor#:~:text=What%20are%20Cursor%20rules%3F%20In,obey%20them%20in%20its%20suggestions)) ([Best Practices for Using PRDs with Cursor | ChatPRD Resources](https://www.chatprd.ai/resources/PRD-for-Cursor#:~:text=))  
- Cursor Community Forum – *Advice on organizing design/requirement docs as rules* ([Design document & wireframes - Discussion - Cursor - Community Forum](https://forum.cursor.com/t/design-document-wireframes/49086#:~:text=You%20can%20structure%20all%20of,and%20accessible%20to%20the%20AI)) ([Design document & wireframes - Discussion - Cursor - Community Forum](https://forum.cursor.com/t/design-document-wireframes/49086#:~:text=1,detailed%20specs%20using%20%40file%20syntax))  
- Cursor Community Forum – *Using a Markdown task list to track features* ([Mastering Long Codebases with Cursor, Gemini, and Claude: A Practical Guide - How To - Cursor - Community Forum](https://forum.cursor.com/t/mastering-long-codebases-with-cursor-gemini-and-claude-a-practical-guide/38240#:~:text=and%20architecture.%20,answers%20received%2C%20and%20decisions%20made)) ([Mastering Long Codebases with Cursor, Gemini, and Claude: A Practical Guide - How To - Cursor - Community Forum](https://forum.cursor.com/t/mastering-long-codebases-with-cursor-gemini-and-claude-a-practical-guide/38240#:~:text=This%20file%20is%20your%20project%E2%80%99s,priorities%2C%20and%20any%20relevant%20notes))  
- Builder.io – *“How I use Cursor”* (on AI writing tests and verifying code) ([How I use Cursor (+ my best tips)](https://www.builder.io/blog/cursor-tips#:~:text=match%20at%20L544%20Here%27s%20where,at%20least%20doing%20something%20right)) ([How I use Cursor (+ my best tips)](https://www.builder.io/blog/cursor-tips#:~:text=Cursor%20and%20say%2C%20,until%20all%20the%20tests%20pass))  
- Namanyay Goel’s Blog – *“My Cursor AI Workflow That Actually Works”* (on effective rules) ([My Cursor AI Workflow That Actually Works | N’s Blog](https://nmn.gl/blog/cursor-guide#:~:text=,and%20logs%20before%20making%20changes)) ([My Cursor AI Workflow That Actually Works | N’s Blog](https://nmn.gl/blog/cursor-guide#:~:text=,needed%20to%20gather%20more%20information))  
- Rapid Developers Blog – *Generating Jest tests with Cursor*